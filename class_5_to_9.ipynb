{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5483d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to test different techniques to improve quality of our response\n",
    "# 1 - Multi Query: Generate different perspectives of the question to improve retrieval\n",
    "# 2- Rag Fusion: Generate multiple search queries from a single question to improve retrieval\n",
    "# 3- Decomposition: Decompose the question into sub-questions to improve answer quality\n",
    "# 4- RAG on sub-questions: Apply RAG on each sub-question to improve answer quality\n",
    "# 5- RAG Fusion on sub-questions: Apply RAG Fusion on each sub-question to improve answer quality\n",
    "# 6- RAG on sub-questions with background knowledge: Apply RAG on each sub-question with background knowledge to improve answer quality\n",
    "# 7- RAG Fusion on sub-questions with background knowledge: Apply RAG Fusion on each sub-question with background knowledge to improve answer quality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16b3f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = xxxx\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata \n",
    "\n",
    "import glob\n",
    "from langchain.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52d19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in vectorstore: 73\n"
     ]
    }
   ],
   "source": [
    "# Indexing \n",
    "doc_path = \"/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf\"\n",
    "loader = DoclingLoader(file_path=doc_path)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "chunks = filter_complex_metadata(chunks) \n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(f\"Number of documents in vectorstore: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86eef372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOllama(model=\"llama3\") \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1cfb9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13654/3983205398.py:7: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = \"If I start my chess game playing D4, what moves my opponent can play? What I can play after?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f968f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"This simple and natural developing move al\\xad ready constituted the main line of the Queen's Gambit Declined as far back as the 19th century and this  situation  has  never really  changed.  A subtle modern variation on it is 3... ~e7. This move is  intended  to  limit  the  opponent's  op\\xad tions. If White continues 4l2Jf3 then Black will simply  play  4...l2Jf6 and  return  to  the  main lines. By preventing ~g5, if  only for one move, Black  hopes  to  take  the  sting  out  of the  Ex\\xad change Variation. It is precisely here, however, that the critical test for  3... ~e7 lies,  for  White can return the favour by playing 4 cxd5 exd5 5 ~f4. Because Black has already put his bishop on e7, the natural reply 5... ~d6 is now slightly less attractive (though it is still not bad and ac\\xad tually  played  quite  often)  which  means  that Black  is  also  limited  in  his  choices.  He  will want  to  develop  his  queen's  bishop  to  f5  but first 5...c6 6 e3 ~f5 7 g4 and secondly 5...l2Jf6 6\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"After  1 d4  d5  things  are  very  different be\\xad cause Black's  pawn on d5 is securely defended. Yet on closer inspection it tums out that White is able  to attack  Black's central  stronghold, mainly because of the possibility of 2 c4. This attack  has  a  different  feel  and  is  slower  than White's plans in the equivalent position after 1 e4 e5. It is based on a long-term positional plan and therefore more of a strategic nature. That is why 1 d4 did not really nourish until the rise of positional  play  in  the  late  19th century.  Until then  1 e4 was by far the most popular move.\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content='A large number of moves  have  grown into major variations here. 9 .\\\\te3, 9 .\\\\tf4, 9 b3 and even the at first sight rather unimpressive 9 a3 are not bad, yet the outstanding main lines are 9 dxc5.\\\\txc5 10 .\\\\tg5 and 9 .\\\\tg5. After the latter move, Black has a choice of 9....\\\\te6, 9...c4 and 9...cxd4 10 CiJxd4 h6.  Some of these lines have been analysed deep into  the endgame, but this should  not  be  as  alarming  as  it  sounds  since play  is  of  a  very  logical  nature  here  which makes the variations fairly easy to understand.'),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content='It is therefore of the utmost importance for a chess-player to find his own personal balance be\\xad tween knowing too much and knowing too little. The purpose of studying opening theory should not be accumulating any set amount of  knowledge, but being content with whatever knowledge one has. For someone with a natural flair for study, it may be perfect to work on openings all the time. For someone who is much less scientifically minded, even the slightest attempt to study openings may well be superfluous and even detrimental to his game.'),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"The  third  plan  (and  the  most  popular  one nowadays), is  actually a refinement of the sec\\xad ond. White waits for 8...JLb7  to be played (this can be done in numerous ways, the most com\\xad mon ones  being 8 JLd3,  8  JLe2,  8  Mel  and  8 '~b3), he then exchanges bishop for knight on f6 and only then does he take on d5. In this type of middIegame  it  is  much  more  difficult  for Black to free his position by means of ...c5 and if he does not achieve this pawn-break he runs the risk of  ending up in a slightly passive, if  still fairly solid position. Naturally by giving up the bishop-pair White does  take  a certain  amount of long-term  positional  risk,  so  this  strategy, popular though it is, does require a steady hand.\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content='The solid option is 6 g3 (D).\\nR\\nI\\nWhite follows  a  completely different  strat\\xad egy  here.  Instead  of trying  to  establish  some sort of  central dominance, he aims for a symmet\\xad rical position with  a  tiny  lead  in  development and  some pressure against b7.  After 6...cxd4, for  instance,  7  CUxdS! ~xdS 8 \"\\'i\\'xd4  \"\\'i\\'xd4  9 \\'\\'Uxd4  is  considered  to  be  very  slightly  better for White. Theory at  any rate prefers 6...4:Jc6 7 i,g2 and now 7.. ,cxd4 (7....ie7 80-0 brings us to  a  position  discussed  via  the  Keres-Parma Variation of the English Opening on page 210) whereupon 8l2Jxd4 (8 ~xdS? \"\\'i\\'xdS would now simply lose a pawn) 8...4:Jxc3 9 bxc3 0Jxd4 10'),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"Queen's Gambit Declined\\n1\\nd4\\nd5\\n2\\nc4\\ne6\\nThe Queen's Gambit Declined is one of the oldest 1 d4 openings and has a long history. As long ago as the 19th century, when 1 e4 was still by  far  the  most popular move,  1...dS  2 c4  e6 was the accepted reply to the far less respected I d4.  With  the rise of positional chess,  atten\\xad tion  shifted  heavily  to I d4  and  the  Queen's Gambit  Declined  automatically  became  the most important  of all  openings.  In  the  1927 match for  the World  Championship  between Alekhine  and  Capablanca,  for  instance,  the Queen's Gambit  Declined was played in 32 of the 34 games (and 1 e4 only once). No doubt as  a  reaction  to  this  one-sidedness,  a  much broader range of  openings was developed after this,  but the Queen's Gambit Declined has al\\xad ways remained important, simply because it is regarded  as  an  intrinsically  sound  and  trust\\xad worthy way of playing.\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"6 ct'lf3 (D)\\nThis  is  the  starting point for  all  variations which are based on 4...i.e7. In the course of well over a century the following can be said to  have evolved  as  the main lines:  6...t2Jbd7, 6...h6 7 iLh4 ct'le4, 6...h6 7 i.h4 b6 and 6...h6 7 i.xf6.\\nB\\ni\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content='But in most cases an assessment is merely a temporary stop. The moment somebody starts ques tioning it, the argument continues. Until the next temporary stop is reached.\\nAnd so, ever since the beginnings of chess, every single chess-player has contributed something to that gigantic construction called opening theory. This brings us to the next question.'),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"It could be said then, that opening theory does not really exist, at least not as something separat from other aspects of the game. Ultimately, opening theory comprises all theory.\\nHowever, since the human brain and even the computer is still not capable of completely seein through (and thereby destroying) chess as a whole, in practice opening theory does not end with a empty board but in positions where there is a certain consensus about how they should be assesse for instance 'chances are equal' or 'White (or Black) has the advantage'.\\nSometimes a question can be answered with total confidence. In the position after 1 e4 there i some room for discussion on how good or bad 1...g5 is (though not much), but if White continues d4 here, there can be no question on the value of 2...f6 because 3 '~h5# is then mate. End of gam end of theory.\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"Since  then,  the  evaluation  of  the  isolated queen's pawn has changed considerably. Pawns may become weak,  especially  when  they  are isolated.  The judging of these  positions  could be said to  have become a very personal affair and it is only natural that some famous grand\\xad masters  have  often  and successfully used the TalTasch  Defence  (for  example,  Spassky  and Kasparov) while others have never even tried it.\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content='This means that opening theory arises quite naturally with the start of a game. No one can avoi it.  It ends, equally naturally, with the end of a game. If we pursue our thinking about the openin position logically and systematically, while accepting only the highest possible degree of  certaint as a satisfactory result, we cannot end our investigation unless we are sure we have reached either winning or a drawn position. Seen in this light, thinking about the starting position involves a thor ough examination of the middlegame and endgame as well.\\nIt could be said then, that opening theory does not really exist, at least not as something separat from other aspects of the game. Ultimately, opening theory comprises all theory.'),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"Black prepares to  recapture on dS  with his e-pawn  if necessary,  while  at  the  same  time opening a diagonal for the king's bishop.  He thus holds his ground in the centre and sets up a  very  natural  plan  of  development  for  his pieces.\\nWhite now has two plausible moves, 3 I.l:lc3 and 31.l:lf3. The main significance of 3 I.l:ln  lies in preparing the Catalan Opening, which arises after 3...l.l:lf6  4 g3  and will be dealt with at the end of this chapter.\\n<!-- formula-not-decoded -->\\nThis is the most usual move, which brings us to  our first major parting of the ways:\\nWith 3...c5 Black claims  an  equal  share  of the centre at once. This is called the Tarrasch Defence.\\nHe can also play 3...c6.  This move is based on a very clever idea and is much more aggres\\xad sive  than  it  looks.  This  is  the  Noteboom  (or Abrahams) Variation.\\nB\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"Queen's Gambit Declined\\nFinally, the move 3....ltb4 has  been played on and off, especially in the  1990s. This is  an attempt to combine two different openings, the Queen's Gambit  Declined  and  the  Nimzo\\xad Indian Defence. Black keeps all options open to go either way depending on White's  reply, a strategy  that  may  well  unsettle  an  opponent with a narrow opening repertoire.  Theory has not yet managed to get a firm grip on this line, but one of White's best options seems to  be 4 a3.  By forcing his opponent's hand, White at\\xad tempts  to  turn  the  situation  around  and  use whatever Black plays (after 4...i.xc3+ S bxc3) to  achieve a favourable variation of the NinlZo\\xad Indian.\"),\n",
       " Document(metadata={'source': '/home/sersasj/rag-exploration/docs/FCO_Fundamental_Chess_Openings-1-20.pdf'}, page_content=\"1 d4 (D)\\n1...d5, 1...tDf6 and 1...f5 are moves that pre\\xad vent the opponent from taking up the ideal cen\\xad tral pawn-formation by playing 2 e4,  which is what  White  would  undoubtedly  do  if Black were to push his clock without making a move. And yet, the term 'ideal  central pawn-formation' is  perhaps  a  misleading  one. It is  not  only  a matter  of how White  (or  Black)  places  his pawns in the centre, it is equally important (and perhaps  even  more  so)  what  he  can do with those  centre  pawns  in  any  given  situation.  A broad  pawn-centre  can  be  strong,  but it  can also be vulnerable. It is  strong if it cramps the enemy position or if it forms a base for an at\\xad tack. It is vulnerable if  it is being attacked, and it is  weak when it crumbles as  a result of that attack.\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0278cfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to the provided context, if you start your chess game by playing 1. d4 (D), your opponent's possible moves are:\\n\\n* 1...d5\\n* 1...tDf6\\n* 1...f5\\n\\nThese moves prevent White from taking up the ideal central pawn-formation by playing 2. e4.\\n\\nAs for what you can play after, it depends on your opponent's response. However, based on the provided context, here are some possible moves:\\n\\nIf your opponent plays:\\n\\n* 1...d5: You can respond with 2. e4 or other moves that aim to control the center and develop your pieces.\\n* 1...tDf6: You can play 2. c3, which is a common response in the Queen's Gambit Declined.\\n* 1...f5: You can respond with 2. g3, which leads to a position that will be dealt with at the end of this chapter (presumably referring to the Catalan Opening).\\n\\nPlease note that these are just possible moves and not exhaustive strategies. The actual moves you play will depend on your opponent's responses and your overall chess strategy.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19af1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (4 queries):\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47e39405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion \n",
    "    | ChatOllama(model=\"llama3\")\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d16116c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula: 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6632f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided context, if you start your chess game with the move D4 (1. d4), your opponent can respond with:\\n\\n* 1...d5 (a common response)\\n\\nAfter this response, you can play:\\n\\n* 2. c4 (according to the text, \"things are very different because Black\\'s pawn on d5 is securely defended. Yet on closer inspection it turns out that White is able to attack Black\\'s central stronghold, mainly because of the possibility of 2 c4.\")\\n\\nPlease note that this is just one possible response and continuation. Chess is a complex game with many variations, and there are many other moves your opponent can play and you can respond with.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a34ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposition\n",
    "\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d421eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "# Chain\n",
    "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "question = \"If I start my chess game playing D4, what moves my opponent can play? What I can play after?\"\n",
    "\n",
    "# Run\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a69eb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c175cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "# llm\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    \n",
    "    rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \n",
    "     \"question\": itemgetter(\"question\"),\n",
    "     \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "    | decomposition_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "    answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a92d538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13654/1381747061.py:23: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(sub_question)\n"
     ]
    }
   ],
   "source": [
    "# Answer each sub-question individually \n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG prompt\n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "    \n",
    "    # Use our decomposition / \n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
    "    \n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "    \n",
    "    for sub_question in sub_questions:\n",
    "        \n",
    "        # Retrieve documents for each sub-question\n",
    "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
    "        \n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs, \n",
    "                                                                \"question\": sub_question})\n",
    "        rag_results.append(answer)\n",
    "    \n",
    "    return rag_results,sub_questions\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
